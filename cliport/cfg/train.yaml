# Training

defaults:
  - config

hydra:
  run:
    dir: ${train.train_dir}

dataset:
  type: 'single' # 'single' or 'multi'
  images: True
  cache: True # load episodes to memory instead of reading from disk
  augment:
    theta_sigma: 60 # rotation sigma in degrees; N(mu = 0, sigma = theta_sigma).

train:
  # folders
  exp_folder: exps
  exp_note: note
#  train_dir: ${root_dir}/${train.exp_folder}/${train.task}-${train.agent}-n${train.n_demos}-train
#  data_dir: ${root_dir}/data  # asdf: /${train.task}
  train_dir: ${train.exp_folder}/${train.task}-${train.agent}-n${train.n_demos}-train-batchify/gpu${train.gpu}-bs${train.batch_size}-lr${train.lr}-${train.exp_note}/
  data_dir: /mounts/work/shengqiang/projects/2023/cliport/${train.task}/

  # task configs
  task: packing-boxes-pairs-seen-colors
  agent: two_stream_full_clip_lingunet_lat_transporter
  n_demos: 1000
  n_steps: 601000 # use 601000 for multi-task models

  # hyper params
  n_rotations: 36
  n_rotations_pick: 1  # FIXME: this should be integrated into the code (where n_rotations is hard-coded as 1)
  batchnorm: False # important: False because batch_size=1
  lr: 1e-4  # should scale with effective batch_size?
  gpu: [0] # -1 for all
  accum_grad: 1
  batch_size: 4

  attn_stream_fusion_type: 'add'
  trans_stream_fusion_type: 'conv'
  lang_fusion_type: 'mult'

  # script configs
  log: True # log metrics and stats to wandb
  n_val: 100
  val_repeats: 1
  save_steps: [500, 1000, 1500, 2000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]
  load_from_last_ckpt: False

  # seed
  seed: 42

wandb:
  run_name: 'cliport0'
  logger:
    entity: cliport
    project: cliport
    tags: []
    group: train
    offline: False
  saver:
    upload: False
    monitor: 'val_loss'